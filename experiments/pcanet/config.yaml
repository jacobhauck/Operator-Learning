n_modes:
  - 8
  - 8
x_min:
  - 0.0
  - 0.0
x_max:
  - 1.0
  - 1.0
num_samples: 256
batch_size: 8
num_pca_modes: 5

u_num_modes: &u_num_modes 16
v_num_modes: &v_num_modes 16

approximator:
  name: MLP
  d_in: *u_num_modes
  d_out: *v_num_modes
  hidden_layers:
    - 128
    - 128
    - 128
  activation:
    name: ReLU

training:
  lr: 0.001
  iterations: 5000
  batch_size: 1
  dataset_size: 1000

